## PR #0006: Live Token Counting (UI + Core)

- Branch: feat/tokens@claude
- Author/Agent: claude (completed by codex)
- Scope: feat
- Summary: Implemented real-time token counting using a pluggable service and UI component. Added a server-safe tiktoken integration with client-side heuristic fallback, a React hook with debounce, and integrated the counters into the Home page. Ensured tests, types, linting, and builds remain green.

### Touched Areas
- lib/tokens/
  - index.ts: TokenCountingService with caching and LRU eviction
  - tiktoken.ts: TikTokenCounter (server-only tiktoken, client heuristic fallback)
- hooks/useTokenCount.ts: Debounced counting with loading/error state and multi-text variant
- components/TokenCounter.tsx: Display component + Compact variant
- app/page.tsx: Integrated live counters and enabled textareas for demo
- __tests__/components/TokenCounter.test.tsx: UI tests for states and formatting
- __tests__/lib/tokens/*.test.ts: Service and tiktoken behavior tests
- __tests__/app/page.test.tsx: Updated expectations for enabled textareas and counters
- next.config.mjs: Enabled async WebAssembly experiments for tokenizer compatibility

### Test Evidence
```bash
$ pnpm typecheck
✅ No TypeScript errors

$ pnpm lint
✅ No ESLint warnings or errors

$ pnpm test
✅ All suites pass (includes new token tests)

$ pnpm build
✅ Compiled successfully (with wasm experiments enabled)
Routes:
┌ ○ /
├ ○ /_not-found
├ ƒ /api/models
└ ƒ /api/refine
```

### Implementation Notes
- Server-safe tiktoken: only required on server to avoid bundling WASM into client; browser path uses a fast heuristic (max of words vs chars/4), sufficient for UX.
- Hook: Debounced counting and cache reuse; exposes loading, error, and refresh; multi-text variant provided for future use.
- UI: TokenCounter and CompactTokenCounter leverage the hook; accessible labels and subtle loading state.
- Home: Textareas enabled for live demo; action buttons remain disabled until wired to APIs.

### Risks & Mitigations
- WASM bundling: Avoided client-side WASM import; enabled async WebAssembly in Next config for compatibility.
- Token accuracy: Heuristic differs from exact model tokenization; mitigated by pluggable design and server-side accuracy where available.

### Next Steps
- Wire Refine/Reinforce buttons to `/api/refine` with live usage display.
- Add optional model-specific tokenizers and allow switching via settings.
- Persist last selected model and token counts in localStorage as part of history work.

### Contract Compliance
✅ No API changes. Endpoints remain `GET /api/models` and `POST /api/refine`. Patch schema unchanged.

